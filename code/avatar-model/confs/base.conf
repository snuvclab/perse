runner = scripts.runner.Runner
train{
    exps_folder = ../../data/experiments/          # location of experiments folder, use ln -s to link to data disk
    projectname = base
    methodname = base
    dataset_class = datasets.datamodule.Dataset
    model_class = model.avatar_model.Model               
    loss_class = model.loss.Loss
    learning_rate = 1.0e-4                      # learning rate for the model
    learning_rate_cam = 5.0e-4                  # learning rate for latent code
    num_pixels = 2048
    batch_size = 1
    upsample_freq = 5
    plot_freq = 1                               # 몇 epoch마다 plot할건지
    save_freq = 500                             # 몇 iteration마다 save할건지
    log_freq = 50                               # 몇 iteration마다 log할건지
    sched_milestones = [40, 60]                 # decay learning rate in these epochs
    sched_factor = 0.5
    GT_lbs_milestones = [10, 20, 30, 40]        # decay flame regularization in these epcohs
    GT_lbs_factor = 0.5
    optimize_expression = True                   # optimize flame expressions
    optimize_camera = True                       # optimize camera and flame poses, this is important for alignment and numerical results...
    tf32 = False
    randomseed = 42
    optimize_scene_latent_code = True
    latent_code_std = 0.05
    enable_prune = True
    enable_upsample = True
    lora{
        lora_finetuning = False
        lora_finetuning_epoch = 3
        prior_checkpoints_path = ../data/experiments/hair_textprompt_51/hair_textprompt_51/hair_long_curly_blonde_fine_1--Guy_to_hair_short_straight_gray_smooth_1--Guy_num_50/train/checkpoints
        prior_checkpoints_epoch = latest
    }
    accumulation_steps = 1
    diffmorpher_target_attrs = [hair, hat]
    training_method{
        train_from_scratch = True
        prior_checkpoints_path = /home/hyunsoocha/GitHub/perse_before_release/data/checkpoints/avatar_model/youngman_checkpoints
        prior_checkpoints_epoch = latest
    }
}
val{
    is_val = True
    val_subdir = { 0 = 0000_beard_balbo_medium_brown_curly_youngman_hyunsoo_img_6948,
                   1 = 0100_cloth_vintage_suit_green_solid_youngman_hyunsoo_img_6948, 
                   2 = 0272_eyebrows_thin_flat_brown_long_youngman_hyunsoo_img_6948, 
                   3 = 0498_hair_shoulder-length_curly_gray_silky_youngman_hyunsoo_img_6948, 
                   4 = 0499_hair_chin-length_shaved_auburn_frizzy_youngman_hyunsoo_img_6948, 
                   5 = 2492_hat_cowboy_hat_wool_green_polka_dot_sporty_youngman_hyunsoo_img_6948, 
                   6 = 2902_mouth_large_thin_lips_red_lips_a_crooked_smile_youngman_hyunsoo_img_6948,
                   7 = 3016_nose_hooked_petite_upturned_average_width_subtle_bridge_asymmetrical_nostrils_youngman_hyunsoo_img_6948}
}
test{
    test_frame_rate = 30 
    selected_frames = all           # all, [1:5], [1, 3, 5] 이렇게 가능
    default{
        rendering = True
        rendering_novel_view = False
        novel_view_euler_angle = [0, 15, 0]
        novel_view_translation = [0, 0, 0]
    }
    rendering_zero_to_one = False
    interpolation{
        rendering = False
        rendering_same_time = False
        # target_list = [hair_long_ponytail_auburn_fine_1--Guy, hair_short_straight_gray_smooth_1--Guy]
        pair_files = /home/hyunsoocha/GitHub/perse-dev/interp_pairs_youngman_supp.txt
        num_frames = 10
    }
    zero_shot{
        rendering = True
        image_path = /home/hyunsoocha/GitHub/perse-dev/data/datasets/hair_textprompt_201/hair_textprompt_201/hair_shoulder-length_shaved_auburn_fine_1--Guy/image
        category = hair
        text_prompt = "A person with shoulder-length, shaved, auburn, fine hair" 
    }
    lora{
        checkpoints = 24
    }
    random_sampling{
        rendering = False
        category = hat
        n_samples = 10
        std = 0.27
    }
}
loss{
    mask_weight = 1.0
    lbs_weight = 10.0
    eikonal_weight = 0.0
    sdf_consistency_weight = 0.0
    ssim_weight = 0.25
    vgg_feature_weight = 0.1
    latent_kl_divergence_weight = 0.1
    normal_weight = 0.0
    diffmorpher_weight = 0.0
}
dataset{
    data_folder = ../../data/datasets
    subject_name = supp_video
    dataset_name = synthetic_dataset
    pattern_type = portrait
    flame_json_name = flame_params.json
    prompt_csv_name = prompt.csv
    use_mean_expression = True                  # canonical expression is set to the mean expression of the training dataset
    use_var_expression = True                   # used for blendshape regularization. Apply less regularization when expression variance is large.
    canonical_pose = 0.4                        # canonical pose is set to zero, except the jaw opening
    category_latent_dim = 16
    reference_image_frame = 1
    num_sample_frames = -1
    num_samples = -1                        # for diffmorpher interpolation finetuning
    bg_color_rendering = white
    category_dict = {   
        beard = 0,
        cloth = 1,
        earrings = 2,
        eyebrows = 3,
        hair = 4,
        hat = 5,
        headphones = 6,
        mouth = 7,
        nose = 8,
        skin = 9,
    }
    source_category = [cloth, eyebrows, hair, mouth, nose, skin]
    segment = {
        background = 0,
        skin = [1, 12],     # skin and neck
        nose = 2,
        eyes = [3, 4],
        eyebrows = [5, 6],
        ears = [7, 8],
        earrings = [7, 8, 18],
        mouth = [9, 10, 11],
        hair = 13,
        beard = 14,
        cloth = 15,
        eyeglasses = 16,
        hat = 17,          # originally headwear
        facewear = 18,
        headphones = [13, 17, 18]
    }
    train{
        sub_dir = all
        img_res = [512, 512]
        subsample_type = ratio   
        subsample = 1
        load_images = False
    }
    val{
        sub_dir = [hair_long_curly_platinum_fine_1--Guy]
        img_res = [512, 512]
        subsample_type = ratio   
        subsample = 50
        load_images = False
        shape_test = hair_long_curly_platinum_fine_1--Guy
    }
    test{
        sub_dir = [test_hyunsoo]      
        img_res = [512, 512]
        subsample_type = ratio   
        subsample = 1
        load_images = False
        shape_test = hair_buzz_cut_coily_blue_frizzy_1--Guy
    }
    
}
model{
    prune_thresh = 0.5
    scene_latent_dim = 32
    binary_segmentation = False
    FLAME_class = flame.FLAME.FLAME
    lora_class = model.lora.LoRALinearLayer
    geometry_class = model.geometry_network.GeometryNetwork
    gaussian_class = model.gaussian_network.GaussianNetwork
    deformer_class = model.deformer_network.ForwardDeformer
    pointcloud_class = model.point_cloud.PointCloud
    clip_regression_class = model.clip_regression_network.CLIPRegressionNetwork
    geometry_network
    {
        d_in = 3
        d_out = 1
        feature_vector_size = 3
        dims = [512, 512, 512, 512, 512, 512, 512, 512, 512]        # IMAvatar 8 layers -> 9 layers
        geometric_init = True
        bias = 0.6
        skip_in = [4]
        weight_norm = True
        multires = 6
    }
    rendering_network
    {
        d_in = 3
        feature_vector_size = 0
        d_out = 3
        dims = [512, 512]                                           # IMAvater 4 layers -> 2 layers
        weight_norm = True
        multires_view = 0
        multires_pnts = 0
    }
    gaussian_network
    {
        d_in = 3
        feature_vector_size = 0
        d_out = 8
        dims = [128, 128, 128]
        weight_norm = True
        multires_view = 0
        multires_pnts = 0
    }
    deformer_network
    {
        d_in = 3
        dims = [128, 128, 128, 128]                                 # same as IMAvatar
        weight_norm = True
        multires = 0
	    num_exp = 50
	    ghostbone = True
	    deform_c = True
        deform_cc = True
    }
    clip_regression_network
    {
        d_in = 1024
        d_out = 32
        dims = [512, 512]
    }
    upsampler_network
    {
        input_dim = 32
        output_dim = 3
        network_capacity = 32
    }
    point_cloud
    {   
        n_init_points = 400
        init_radius = 0.5 
        max_points = 100000 
    }
}
